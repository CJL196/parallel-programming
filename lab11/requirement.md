## 任务1：
在信号处理、图像处理和其他工程/科学领域，卷积是一种使用广泛的技术。在深度学习领域，卷积神经网络(CNN)这种模型架构就得名于这种技术。在本实验中，我们将在GPU上实现卷积操作，注意这里的卷积是指神经网络中的卷积操作，与信号处理领域中的卷积操作不同，它不需要对Filter进行翻转，不考虑bias。
任务一通过CUDA实现直接卷积（滑窗法），输入从256\*256增加至4096\*4096或者输入从32\32增加至512\*512.
输入：Input matrix size和Kernel size, 例如 32 和 3
问题描述：用直接卷积的方式对Input进行卷积，这里只需要实现2D, height\*width，通道channel(depth)设置为3，Kernel (Filter)大小设置为3\*3，kernel channel(depth)设置为3，步幅(stride)分别设置为1，2，3，可能需要通过填充(padding)配合步幅(stride)完成CNN操作。注：实验的卷积操作不需要考虑bias(b)，bias设置为0.
输出：输出卷积结果以及计算时间

## 任务2：
任务二使用im2col方法结合上次实验实现的GEMM实现卷积操作。输入从256\*256增加至4096\*4096或者输入从32\*32增加至512\*512，具体实现的过程可以参考下面的图片和参考资料。
输入：Input matrix size和Kernel size, 例如 32 和 3
问题描述：用直接卷积的方式对Input进行卷积，这里只需要实现2D, height\*width，通道channel(depth)设置为3，Kernel (Filter)大小设置为3\*3，kernel channel(depth)设置为3，步幅(stride)分别设置为1，2，3，可能需要通过填充(padding)配合步幅(stride)完成CNN操作。注：实验的卷积操作不需要考虑bias(b)，bias设置为0.
输出：卷积结果和时间。

任务3：
NVIDIA cuDNN是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。
使用cuDNN提供的卷积方法进行卷积操作，记录其相应Input的卷积时间，与自己实现的卷积操作进行比较。如果性能不如cuDNN，用文字描述可能的改进方法。
